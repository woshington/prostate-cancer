{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:19.224903Z",
     "start_time": "2025-03-01T19:13:17.821903Z"
    }
   },
   "source": [
    "from torch import nn, load as torch_load\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from efficientnet_pytorch import model as efficientnet_model\n",
    "from tqdm import tqdm\n",
    "from skimage import io as skio, color\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:19.240682Z",
     "start_time": "2025-03-01T19:13:19.228810Z"
    }
   },
   "source": [
    "output_dimensions = 5\n",
    "data_dir = '../dataset'\n",
    "images_dir = os.path.join(data_dir, 'tiles')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "df_test = pd.read_csv(f\"data/clean/test.csv\")\n",
    "\n",
    "# df_pen_mask = pd.read_csv(\"data/without_pen_mask.csv\")\n",
    "# df_test = df_test[~df_test['image_id'].isin(df_pen_mask['image_id'])]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:19.417550Z",
     "start_time": "2025-03-01T19:13:19.413963Z"
    }
   },
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Classe que implementa a arquitetura EfficientNet\n",
    "\n",
    "        Parâmetros:\n",
    "            backbone: str\n",
    "                Nome do modelo de EfficientNet a ser utilizado\n",
    "            output_dimensions: int\n",
    "                Número de neuronios na camada de saída\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dimensions):\n",
    "        super().__init__()\n",
    "        self.efficient_net = efficientnet_model.EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
    "        # self.efficient_net.load_state_dict(\n",
    "        #     torch_load(\"pre-trained-utils/efficientnet-b0_segmented_fold_2_without_pen.pth\", weights_only=True)\n",
    "        # )\n",
    "        self.fully_connected = nn.Linear(self.efficient_net._fc.in_features, output_dimensions)\n",
    "        self.efficient_net._fc = nn.Identity()\n",
    "\n",
    "    def extract(self, inputs):\n",
    "        return self.efficient_net(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.extract(inputs)\n",
    "        x = self.fully_connected(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:19.467712Z",
     "start_time": "2025-03-01T19:13:19.463667Z"
    }
   },
   "source": [
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, root_dir, dataframe, transforms=None):\n",
    "        self.root_dir = root_dir \n",
    "        self.dataframe = dataframe\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        img_id = row.image_id.strip()\n",
    "        \n",
    "        file_path = os.path.join(self.root_dir, f'{img_id}.jpg')\n",
    "        tile_image = skio.imread(file_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            tile_image = self.transforms(image=tile_image)['image'] \n",
    "\n",
    "        tile_image = tile_image.astype(np.float32) / 255.0 \n",
    "        tile_image = np.transpose(tile_image, (2, 0, 1))\n",
    "\n",
    "        label = np.zeros(5).astype(np.float32)\n",
    "        label[:row.isup_grade] = 1.\n",
    "        \n",
    "        return torch.tensor(tile_image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:19.850623Z",
     "start_time": "2025-03-01T19:13:19.526095Z"
    }
   },
   "source": [
    "model = EfficientNet(output_dimensions)\n",
    "model.load_state_dict(\n",
    "    torch_load(\n",
    "        \"pre-trained-models/clean/fold_4.pth\",\n",
    "        weights_only=True,\n",
    "        map_location=device\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:19.866913Z",
     "start_time": "2025-03-01T19:13:19.860315Z"
    }
   },
   "source": [
    "def calculate_metrics(preds, targets, df):\n",
    "    accuracy = (preds == targets).mean() * 100. # Calcula a acurácia em porcentagem\n",
    "    quadraditic_weighted_kappa = cohen_kappa_score(preds, targets, weights='quadratic') # Calcula o kappa quadrático ponderado dos dados em geral\n",
    "\n",
    "    quadraditic_weighted_kappa_karolinska = cohen_kappa_score(preds[df['data_provider'] == 'karolinska'], df[df['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n",
    "    quadraditic_weighted_kappa_radboud = cohen_kappa_score(preds[df['data_provider'] == 'radboud'], df[df['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n",
    "\n",
    "    return accuracy, quadraditic_weighted_kappa, quadraditic_weighted_kappa_karolinska, quadraditic_weighted_kappa_radboud\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    bar_progress = tqdm(dataloader)\n",
    "\n",
    "    all_logits = []\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (batch_data, batch_targets) in enumerate(bar_progress):           \n",
    "            batch_data, batch_targets = batch_data.to(device), batch_targets.to(device)\n",
    "\n",
    "            logits = model(batch_data)\n",
    "            \n",
    "\n",
    "            prediction = logits.sigmoid()\n",
    "            prediction = prediction.sum(1).detach().round()\n",
    "        \n",
    "            all_logits.append(logits)\n",
    "            preds.append(prediction)\n",
    "            targets.append(batch_targets.sum(1))           \n",
    "\n",
    "        \n",
    "    all_logits = torch.cat(all_logits).cpu().numpy()\n",
    "    preds = torch.cat(preds).cpu().numpy()\n",
    "    targets = torch.cat(targets).cpu().numpy()\n",
    "\n",
    "    accuracy, quadraditic_weighted_kappa, quadraditic_weighted_kappa_karolinska, quadraditic_weighted_kappa_radboud = calculate_metrics(preds, targets, df_test)\n",
    "\n",
    "    return {\n",
    "        \"val_acc\":accuracy, \n",
    "        \"quadraditic_weighted_kappa\":quadraditic_weighted_kappa, \n",
    "        \"quadraditic_weighted_kappa_karolinska\":quadraditic_weighted_kappa_karolinska, \n",
    "        \"quadraditic_weighted_kappa_radboud\":quadraditic_weighted_kappa_radboud\n",
    "    }  "
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:23.158309Z",
     "start_time": "2025-03-01T19:13:19.918774Z"
    }
   },
   "source": [
    "dataset_test = PandasDataset(images_dir, df_test, transforms = None)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=2, shuffle=False)\n",
    "response = evaluation(model, dataloader_test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/747 [00:02<01:53,  6.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset_test \u001B[38;5;241m=\u001B[39m PandasDataset(images_dir, df_test, transforms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m      2\u001B[0m dataloader_test \u001B[38;5;241m=\u001B[39m DataLoader(dataset_test, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mevaluation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 21\u001B[0m, in \u001B[0;36mevaluation\u001B[0;34m(model, dataloader)\u001B[0m\n\u001B[1;32m     18\u001B[0m targets \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m index, (batch_data, batch_targets) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(bar_progress):           \n\u001B[1;32m     22\u001B[0m         batch_data, batch_targets \u001B[38;5;241m=\u001B[39m batch_data\u001B[38;5;241m.\u001B[39mto(device), batch_targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     24\u001B[0m         logits \u001B[38;5;241m=\u001B[39m model(batch_data)\n",
      "File \u001B[0;32m~/Projects/Doutorado/venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/Doutorado/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m~/Projects/Doutorado/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T19:13:23.160000302Z",
     "start_time": "2025-02-12T03:53:18.192649Z"
    }
   },
   "source": [
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_acc': 63.788487282463194,\n",
       " 'quadraditic_weighted_kappa': 0.8655803972337013,\n",
       " 'quadraditic_weighted_kappa_karolinska': 0.8496141238121936,\n",
       " 'quadraditic_weighted_kappa_radboud': 0.8432960049700775}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
