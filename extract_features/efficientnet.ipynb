{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from skimage import io as skio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import model as efficientnet_model\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=\"../../dataset\"\n",
    "data_csv_path=f\"../data\"\n",
    "output_dimensions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{data_csv_path}/train.csv\")\n",
    "df_val = pd.read_csv(f\"{data_csv_path}/val.csv\")\n",
    "df_test = pd.read_csv(f\"{data_csv_path}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ToFloat(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(args):\n",
    "    image_path, label, index, transform, model = args\n",
    "    print(f\"Processando item: {index+1}\")\n",
    "\n",
    "    image = skio.imread(image_path)\n",
    "    \n",
    "    if transform:\n",
    "        image = transform(image=image)[\"image\"]\n",
    "    \n",
    "    # image = torch.from_numpy(image).float()\n",
    "    image /= 255\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    \n",
    "    features = features.flatten(start_dim=1)\n",
    "    features_np = features.squeeze().numpy()\n",
    "    \n",
    "    return features_np, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetFeatureExtractor(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.efficient_net = efficientnet_model.EfficientNet.from_pretrained(\"efficientnet-b0\")        \n",
    "        self.efficient_net.load_state_dict(\n",
    "            torch.load(\"../pre-trained-models/efficientnet-b0-08094119.pth\", weights_only=True)\n",
    "        )\n",
    "        self.efficient_net._fc = nn.Identity()\n",
    "\n",
    "    def extract(self, inputs):\n",
    "        return self.efficient_net.extract_features(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.extract(inputs)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Processando item: 1\n",
      "Processando item: 2\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetFeatureExtractor()\n",
    "model.eval()\n",
    "IMG_DIR = f\"{dataset_dir}/tiles\"\n",
    "\n",
    "params = [\n",
    "    (f\"{IMG_DIR}/{row['image_id']}.jpg\", row['isup_grade'], index, transforms_train, model) \n",
    "    for index, row in df_train.iterrows()\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "  results = list(executor.map(extract_features, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características forma: (2, 2949120)\n",
      "Rótulos forma: (2,)\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "all_labels = []\n",
    "# Coletar as características e rótulos\n",
    "for features, label in results:\n",
    "    all_features.append(features)\n",
    "    all_labels.append(label)\n",
    "\n",
    "# Converter listas para arrays numpy\n",
    "all_features_np = np.array(all_features)\n",
    "all_labels_np = np.array(all_labels)\n",
    "\n",
    "# Verificar as formas\n",
    "print(f\"Características forma: {all_features_np.shape}\")\n",
    "print(f\"Rótulos forma: {all_labels_np.shape}\")\n",
    "\n",
    "# Empilhar as características e as classes em um único array 2D (features + classe)\n",
    "data = np.column_stack((all_features_np, all_labels_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'feaefficientnet_data.npy' gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Salvar os dados em um arquivo .npy\n",
    "np.save('efficientnet_data.npy', data)\n",
    "\n",
    "print(\"Arquivo 'feaefficientnet_data.npy' gerado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
